{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - CSCI544 - Krish Sukhani "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Dataset Creation\n",
    "#### Used the data.tsv file -- Location: Same folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.tsv', on_bad_lines='skip', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>1797882</td>\n",
       "      <td>R3I2DHQBR577SS</td>\n",
       "      <td>B001ANOOOE</td>\n",
       "      <td>2102612</td>\n",
       "      <td>The Naked Bee Vitmin C Moisturizing Sunscreen ...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love this, excellent sun block!!</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>18381298</td>\n",
       "      <td>R1QNE9NQFJC2Y4</td>\n",
       "      <td>B0016J22EQ</td>\n",
       "      <td>106393691</td>\n",
       "      <td>Alba Botanica Sunless Tanning Lotion, 4 Ounce</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Thank you Alba Bontanica!</td>\n",
       "      <td>The great thing about this cream is that it do...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>19242472</td>\n",
       "      <td>R3LIDG2Q4LJBAO</td>\n",
       "      <td>B00HU6UQAG</td>\n",
       "      <td>375449471</td>\n",
       "      <td>Elysee Infusion Skin Therapy Elixir, 2oz.</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great Product, I'm 65 years old and this is al...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>19551372</td>\n",
       "      <td>R3KSZHPAEVPEAL</td>\n",
       "      <td>B002HWS7RM</td>\n",
       "      <td>255651889</td>\n",
       "      <td>Diane D722 Color, Perm And Conditioner Process...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>GOOD DEAL!</td>\n",
       "      <td>I use them as shower caps &amp; conditioning caps....</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>14802407</td>\n",
       "      <td>RAI2OIG50KZ43</td>\n",
       "      <td>B00SM99KWU</td>\n",
       "      <td>116158747</td>\n",
       "      <td>Biore UV Aqua Rich Watery Essence SPF50+/PA+++...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>this soaks in quick and provides a nice base f...</td>\n",
       "      <td>This is my go-to daily sunblock. It leaves no ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US      1797882  R3I2DHQBR577SS  B001ANOOOE         2102612   \n",
       "1          US     18381298  R1QNE9NQFJC2Y4  B0016J22EQ       106393691   \n",
       "2          US     19242472  R3LIDG2Q4LJBAO  B00HU6UQAG       375449471   \n",
       "3          US     19551372  R3KSZHPAEVPEAL  B002HWS7RM       255651889   \n",
       "4          US     14802407   RAI2OIG50KZ43  B00SM99KWU       116158747   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  The Naked Bee Vitmin C Moisturizing Sunscreen ...           Beauty   \n",
       "1      Alba Botanica Sunless Tanning Lotion, 4 Ounce           Beauty   \n",
       "2          Elysee Infusion Skin Therapy Elixir, 2oz.           Beauty   \n",
       "3  Diane D722 Color, Perm And Conditioner Process...           Beauty   \n",
       "4  Biore UV Aqua Rich Watery Essence SPF50+/PA+++...           Beauty   \n",
       "\n",
       "  star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0           5            0.0          0.0    N                 Y   \n",
       "1           5            0.0          0.0    N                 Y   \n",
       "2           5            0.0          0.0    N                 Y   \n",
       "3           5            0.0          0.0    N                 Y   \n",
       "4           5            0.0          0.0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                         Five Stars   \n",
       "1                          Thank you Alba Bontanica!   \n",
       "2                                         Five Stars   \n",
       "3                                         GOOD DEAL!   \n",
       "4  this soaks in quick and provides a nice base f...   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                   Love this, excellent sun block!!  2015-08-31  \n",
       "1  The great thing about this cream is that it do...  2015-08-31  \n",
       "2  Great Product, I'm 65 years old and this is al...  2015-08-31  \n",
       "3  I use them as shower caps & conditioning caps....  2015-08-31  \n",
       "4  This is my go-to daily sunblock. It leaves no ...  2015-08-31  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep Reviews and Ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love this, excellent sun block!!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The great thing about this cream is that it do...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great Product, I'm 65 years old and this is al...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I use them as shower caps &amp; conditioning caps....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is my go-to daily sunblock. It leaves no ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body star_rating\n",
       "0                   Love this, excellent sun block!!           5\n",
       "1  The great thing about this cream is that it do...           5\n",
       "2  Great Product, I'm 65 years old and this is al...           5\n",
       "3  I use them as shower caps & conditioning caps....           5\n",
       "4  This is my go-to daily sunblock. It leaves no ...           5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['review_body', 'star_rating']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_body    400\n",
       "star_rating     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love this, excellent sun block!!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The great thing about this cream is that it do...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great Product, I'm 65 years old and this is al...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I use them as shower caps &amp; conditioning caps....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is my go-to daily sunblock. It leaves no ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094302</th>\n",
       "      <td>After watching my Dad struggle with his scisso...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094303</th>\n",
       "      <td>Like most sound machines, the sounds choices a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094304</th>\n",
       "      <td>I bought this product because it indicated 30 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094305</th>\n",
       "      <td>We have used Oral-B products for 15 years; thi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094306</th>\n",
       "      <td>I love this toothbrush. It's easy to use, and ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5093907 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body star_rating\n",
       "0                         Love this, excellent sun block!!           5\n",
       "1        The great thing about this cream is that it do...           5\n",
       "2        Great Product, I'm 65 years old and this is al...           5\n",
       "3        I use them as shower caps & conditioning caps....           5\n",
       "4        This is my go-to daily sunblock. It leaves no ...           5\n",
       "...                                                    ...         ...\n",
       "5094302  After watching my Dad struggle with his scisso...           5\n",
       "5094303  Like most sound machines, the sounds choices a...           3\n",
       "5094304  I bought this product because it indicated 30 ...           5\n",
       "5094305  We have used Oral-B products for 15 years; thi...           5\n",
       "5094306  I love this toothbrush. It's easy to use, and ...           5\n",
       "\n",
       "[5093907 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### We form three classes and select 20000 reviews randomly from each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ref: https://sparkbyexamples.com/pandas/pandas-replace-values-based-on-condition/#:~:text=You%20can%20replace%20values%20of,the%20values%20of%20pandas%20DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love this, excellent sun block!!</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The great thing about this cream is that it do...</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great Product, I'm 65 years old and this is al...</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I use them as shower caps &amp; conditioning caps....</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is my go-to daily sunblock. It leaves no ...</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body star_rating\n",
       "0                   Love this, excellent sun block!!      class3\n",
       "1  The great thing about this cream is that it do...      class3\n",
       "2  Great Product, I'm 65 years old and this is al...      class3\n",
       "3  I use them as shower caps & conditioning caps....      class3\n",
       "4  This is my go-to daily sunblock. It leaves no ...      class3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['star_rating'] = np.where(data['star_rating'] == '1', 'class1', data['star_rating'])\n",
    "data['star_rating'] = np.where(data['star_rating'] == '2', 'class1', data['star_rating'])\n",
    "data['star_rating'] = np.where(data['star_rating'] == '3', 'class2', data['star_rating'])\n",
    "data['star_rating'] = np.where(data['star_rating'] == '4', 'class3', data['star_rating'])\n",
    "data['star_rating'] = np.where(data['star_rating'] == '5', 'class3', data['star_rating'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class1 = data[data['star_rating'] == 'class1'].sample(n=20000, replace = False)\n",
    "data_class2 = data[data['star_rating'] == 'class2'].sample(n=20000, replace = False)\n",
    "data_class3 = data[data['star_rating'] == 'class3'].sample(n=20000, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([data_class1,data_class2,data_class3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>563295</th>\n",
       "      <td>Pos when you turn it on the tools vibrate out....</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770879</th>\n",
       "      <td>small quantity of each color, not for longwear</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974694</th>\n",
       "      <td>Since when does NEEM oil equal BRAHMI oil??  A...</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662933</th>\n",
       "      <td>Unfortunately the quality was not great. The d...</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885061</th>\n",
       "      <td>What a piece of junk....bought 2 and both are ...</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897100</th>\n",
       "      <td>These are the third Rubis needlenose tweezers ...</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122361</th>\n",
       "      <td>My niece has been wanting this for a while, so...</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529500</th>\n",
       "      <td>Easy to use.</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331023</th>\n",
       "      <td>I got this product as described. My coworkers ...</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010270</th>\n",
       "      <td>This works great. My son has never been sunbur...</td>\n",
       "      <td>class3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body star_rating\n",
       "563295   Pos when you turn it on the tools vibrate out....      class1\n",
       "2770879     small quantity of each color, not for longwear      class1\n",
       "2974694  Since when does NEEM oil equal BRAHMI oil??  A...      class1\n",
       "3662933  Unfortunately the quality was not great. The d...      class1\n",
       "3885061  What a piece of junk....bought 2 and both are ...      class1\n",
       "...                                                    ...         ...\n",
       "897100   These are the third Rubis needlenose tweezers ...      class3\n",
       "2122361  My niece has been wanting this for a while, so...      class3\n",
       "529500                                        Easy to use.      class3\n",
       "1331023  I got this product as described. My coworkers ...      class3\n",
       "4010270  This works great. My son has never been sunbur...      class3\n",
       "\n",
       "[60000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverting the classes to 0, 1, 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['star_rating']=df_new['star_rating'].map({'class1':0,'class2':1, 'class3':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>563295</th>\n",
       "      <td>Pos when you turn it on the tools vibrate out....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770879</th>\n",
       "      <td>small quantity of each color, not for longwear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974694</th>\n",
       "      <td>Since when does NEEM oil equal BRAHMI oil??  A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662933</th>\n",
       "      <td>Unfortunately the quality was not great. The d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885061</th>\n",
       "      <td>What a piece of junk....bought 2 and both are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897100</th>\n",
       "      <td>These are the third Rubis needlenose tweezers ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122361</th>\n",
       "      <td>My niece has been wanting this for a while, so...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529500</th>\n",
       "      <td>Easy to use.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331023</th>\n",
       "      <td>I got this product as described. My coworkers ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010270</th>\n",
       "      <td>This works great. My son has never been sunbur...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body  star_rating\n",
       "563295   Pos when you turn it on the tools vibrate out....            0\n",
       "2770879     small quantity of each color, not for longwear            0\n",
       "2974694  Since when does NEEM oil equal BRAHMI oil??  A...            0\n",
       "3662933  Unfortunately the quality was not great. The d...            0\n",
       "3885061  What a piece of junk....bought 2 and both are ...            0\n",
       "...                                                    ...          ...\n",
       "897100   These are the third Rubis needlenose tweezers ...            2\n",
       "2122361  My niece has been wanting this for a while, so...            2\n",
       "529500                                        Easy to use.            2\n",
       "1331023  I got this product as described. My coworkers ...            2\n",
       "4010270  This works great. My son has never been sunbur...            2\n",
       "\n",
       "[60000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_new['review_body'], df_new['star_rating'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORD EMBEDDINGS\n",
    "\n",
    "### https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py\n",
    "### Task 2a\n",
    "\n",
    "#### Loading google word2vec model and checking for sematic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')\n",
    "# loading the google word2vec dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55674857"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity('excellent', 'outstanding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excellent and Outstanding are 55.6% similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321839332581)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['woman', 'king'], negative=['man'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The equation King + Woman - Man gives Queen as the Most similar answer with 71.1% similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amazing', 0.8282866477966309),\n",
       " ('unbelievable', 0.74649578332901),\n",
       " ('fantastic', 0.7453290224075317),\n",
       " ('incredible', 0.7390913367271423),\n",
       " ('unbelieveable', 0.6678116917610168),\n",
       " ('terrific', 0.654850423336029),\n",
       " ('wonderful', 0.6525596380233765),\n",
       " ('great', 0.6510506868362427),\n",
       " ('fabulous', 0.6416462659835815),\n",
       " ('nice', 0.6404187679290771)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar('awesome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The most similar word to Awesome is Amazing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51953924"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity('brother', 'boy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brother and Boy are 51.9% similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('girl', 0.8881361484527588),\n",
       " ('teenage_girl', 0.7058953642845154),\n",
       " ('mother', 0.6978276968002319),\n",
       " ('toddler', 0.6870075464248657),\n",
       " ('daughter', 0.6686559915542603)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['woman', 'boy'], negative=['man'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The equation Woman + Boy - Man gives Girl as the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 2b\n",
    "#### https://medium.com/@dilip.voleti/classification-using-word2vec-b1d79d375381\n",
    "#### https://tedboy.github.io/nlps/generated/generated/gensim.utils.simple_preprocess.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "train_data = []\n",
    "for i in X_train:\n",
    "    val = simple_preprocess(i, deacc=True)\n",
    "    train_data.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in X_test:\n",
    "    val = simple_preprocess(i, deacc=True)\n",
    "    test_data.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out word2vec model i.e. on our dataset based on the parameters mentioned in the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=train_data, vector_size=300, window=13, min_count=9, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7757139"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('excellent', 'outstanding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excellent and Outstanding are 77.5% Similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amazing', 0.8166578412055969),\n",
       " ('fantastic', 0.7310990691184998),\n",
       " ('wonderful', 0.7234351634979248),\n",
       " ('excellent', 0.6720810532569885),\n",
       " ('great', 0.6694231629371643),\n",
       " ('terrific', 0.6081065535545349),\n",
       " ('delicious', 0.5964312553405762),\n",
       " ('perfect', 0.5868383049964905),\n",
       " ('fabulous', 0.5829119682312012),\n",
       " ('outstanding', 0.5827775597572327)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('awesome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The most similar word to Awesome is Amazing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40999338"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('brother', 'boy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('haired', 0.5567963719367981),\n",
       " ('hispanic', 0.5485888719558716),\n",
       " ('transitioning', 0.5455800890922546),\n",
       " ('female', 0.5215923190116882),\n",
       " ('skinned', 0.5153078436851501)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman', 'boy'], negative=['man'], topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The equation Woman + Boy - Man gives haired as output which is not so good\n",
    "#### Some words not present in out training dataset makes it difficult for the model to find most similar word that is expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The vectors generated by the pretrained google word2vec models ideally perform better as they have a large dataset on which they have been trained on whereas the self-trained model can outperform the pre trained model in the case where there is more training data related to it in the dataset. \n",
    "\n",
    "#### The pretrained model seems to encode semantic similarities better as it has been trained on a large dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task - 3 : Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(wv.index_to_key)\n",
    "X_train_vect = np.array([np.array([wv[i] for i in ls if i in words])for ls in train_data])\n",
    "X_test_vect = np.array([np.array([wv[i] for i in ls if i in words])for ls in test_data])\n",
    "\n",
    "# creating the train and test vectors based on the word existing in the google word2vec dataset i.e their word vector is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(y_train)\n",
    "y_test = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the average training vectors\n",
    "\n",
    "avg_x_train = []\n",
    "avg_y_train = []\n",
    "for i in range(0, len(X_train_vect)):\n",
    "    if len(X_train_vect[i]) > 0:\n",
    "        avg_x_train.append(list(np.mean(X_train_vect[i], axis=0)))\n",
    "        avg_y_train.append(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the average testing vectors\n",
    "\n",
    "avg_x_test = []\n",
    "avg_y_test = []\n",
    "for i in range(0, len(X_test_vect)):\n",
    "    if len(X_test_vect[i]) > 0:\n",
    "        avg_x_test.append(list(np.mean(X_test_vect[i], axis=0)))\n",
    "        avg_y_test.append(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_new[\"review_body\"])\n",
    "y = df_new['star_rating']\n",
    "\n",
    "#Ref: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(random_state=23)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Word2Vec\n",
    "model_wv = Perceptron(tol=1e-3, random_state=23)\n",
    "model_wv.fit(avg_x_train, avg_y_train)\n",
    "\n",
    "#TFIDF\n",
    "model_tf = Perceptron(tol=1e-3, random_state=23)\n",
    "model_tf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Word2Vec\n",
      "0.592712331052895\n",
      "Perceptron TFIDF\n",
      "0.8569791666666666\n"
     ]
    }
   ],
   "source": [
    "print('Perceptron Word2Vec')\n",
    "print(model_wv.score(avg_x_train, avg_y_train))\n",
    "\n",
    "print('Perceptron TFIDF')\n",
    "print(model_tf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_wv = model_wv.predict(avg_x_test)\n",
    "y_pred_tf = model_tf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.87      0.63      3959\n",
      "           1       0.60      0.34      0.43      4012\n",
      "           2       0.82      0.56      0.67      4010\n",
      "\n",
      "    accuracy                           0.59     11981\n",
      "   macro avg       0.64      0.59      0.58     11981\n",
      "weighted avg       0.64      0.59      0.58     11981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec\")\n",
    "print(classification_report(avg_y_test, y_pred_wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      4051\n",
      "           1       0.55      0.52      0.54      3935\n",
      "           2       0.73      0.73      0.73      4014\n",
      "\n",
      "    accuracy                           0.64     12000\n",
      "   macro avg       0.64      0.64      0.64     12000\n",
      "weighted avg       0.64      0.64      0.64     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF\")\n",
    "print(classification_report(y_test, y_pred_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron - Word2Vec (Accuracy)\n",
      "0.5879308905767465\n",
      "Perceptron - TF-IDF (Accuracy)\n",
      "0.638\n"
     ]
    }
   ],
   "source": [
    "print('Perceptron - Word2Vec (Accuracy)')\n",
    "print(accuracy_score(avg_y_test, y_pred_wv))\n",
    "\n",
    "print('Perceptron - TF-IDF (Accuracy)')\n",
    "print(accuracy_score(y_test, y_pred_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron Accuracy (Word2Vec) - 58.79%\n",
    "#### Perceptron Accuracy (TF-IDF) - 63.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=23, tol=0.001)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word2Vec\n",
    "model_wv = LinearSVC(tol=1e-3, random_state=23)\n",
    "model_wv.fit(avg_x_train, avg_y_train)\n",
    "\n",
    "#TFIDF\n",
    "model_tf = LinearSVC(tol=1e-3, random_state=23)\n",
    "model_tf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Word2Vec (Score)\n",
      "0.6676747872517937\n",
      "SVM - TF-IDF (Score)\n",
      "0.8540833333333333\n"
     ]
    }
   ],
   "source": [
    "print('SVM - Word2Vec (Score)')\n",
    "print(model_wv.score(avg_x_train, avg_y_train))\n",
    "\n",
    "print('SVM - TF-IDF (Score)')\n",
    "print(model_tf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_wv = model_wv.predict(avg_x_test)\n",
    "y_pred_tf = model_tf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68      3959\n",
      "           1       0.60      0.56      0.58      4012\n",
      "           2       0.73      0.74      0.74      4010\n",
      "\n",
      "    accuracy                           0.67     11981\n",
      "   macro avg       0.67      0.67      0.67     11981\n",
      "weighted avg       0.67      0.67      0.67     11981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec\")\n",
    "print(classification_report(avg_y_test, y_pred_wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71      4051\n",
      "           1       0.61      0.60      0.61      3935\n",
      "           2       0.79      0.79      0.79      4014\n",
      "\n",
      "    accuracy                           0.70     12000\n",
      "   macro avg       0.70      0.70      0.70     12000\n",
      "weighted avg       0.70      0.70      0.70     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF\")\n",
    "print(classification_report(y_test, y_pred_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Word2Vec (Accuracy)\n",
      "0.6666388448376597\n",
      "SVM - TF-IDF (Accuracy)\n",
      "0.70325\n"
     ]
    }
   ],
   "source": [
    "print('SVM - Word2Vec (Accuracy)')\n",
    "print(accuracy_score(avg_y_test, y_pred_wv))\n",
    "\n",
    "print('SVM - TF-IDF (Accuracy)')\n",
    "print(accuracy_score(y_test, y_pred_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Accuracy (Word2Vec) - 66.6%\n",
    "#### SVM Accuracy (TF-IDF) -70.32%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that TFIDF performs better than Word2Vec in both perceptron as well as SVM. This is because word2vec is usually used for getting the context of the sentence and is computationally intensive whereas TFIDF works on the works and in case of reviews, only words can suffice to identify the sentiment. Further it means that, word2vec here is a general dataset whereas in TFIDF we have a targeted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Feedforward Neural Networks\n",
    "### https://www.kaggle.com/code/mishra1993/pytorch-multi-layer-perceptron-mnist/notebook\n",
    "### Task 4a - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = torch.tensor(avg_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr = torch.tensor(avg_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xts = torch.tensor(avg_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "yts = torch.tensor(avg_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://machinelearningmastery.com/building-multilayer-perceptron-models-in-pytorch/\n",
    "#### hidden layers = 2 (100 and 10 nodes)\n",
    "#### epochs = 20\n",
    "#### Loss - Cross entropy Loss\n",
    "#### Non linearity - Relu and softmax\n",
    "#### Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(Xtr.shape[1], 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.029\n",
      "Epoch 2 loss: 0.028\n",
      "Epoch 3 loss: 0.027\n",
      "Epoch 4 loss: 0.027\n",
      "Epoch 5 loss: 0.027\n",
      "Epoch 6 loss: 0.027\n",
      "Epoch 7 loss: 0.027\n",
      "Epoch 8 loss: 0.027\n",
      "Epoch 9 loss: 0.027\n",
      "Epoch 10 loss: 0.027\n",
      "Epoch 11 loss: 0.027\n",
      "Epoch 12 loss: 0.027\n",
      "Epoch 13 loss: 0.027\n",
      "Epoch 14 loss: 0.027\n",
      "Epoch 15 loss: 0.027\n",
      "Epoch 16 loss: 0.027\n",
      "Epoch 17 loss: 0.027\n",
      "Epoch 18 loss: 0.026\n",
      "Epoch 19 loss: 0.026\n",
      "Epoch 20 loss: 0.026\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, len(Xtr), 32):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(Xtr[i:i+32])\n",
    "        loss = criterion(outputs, ytr[i:i+32])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('Epoch %d loss: %.3f' % (epoch+1, running_loss/len(Xtr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.83\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(Xts)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == yts).sum().item() / len(yts)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for MLP (testing split) - 66.83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating the first 10 words to data_tr\n",
    "\n",
    "data_tr = []\n",
    "for review in df_new['review_body'].tolist():\n",
    "    #print(review)\n",
    "    data_temp = []\n",
    "    for i, word in enumerate(review.split()):\n",
    "        #print(i, word)\n",
    "        if i<10 and word in words:\n",
    "            data_temp.append(wv[word])\n",
    "    if len(data_temp) < 10:\n",
    "        while len(data_temp) != 10:\n",
    "            data_temp.append(np.zeros(shape=(300,)))\n",
    "    data_tr.append(data_temp)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(data_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(df_new['star_rating'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(3000, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "# Create an instance of the MLP model\n",
    "model = MLP()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.view((60000, 3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the MLP model\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        # Get the batch data\n",
    "        batch_X = X_train[i:i+batch_size]\n",
    "        batch_y = y_train[i:i+batch_size]\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, accuracy: 54.74%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = y_test.size(0)\n",
    "    correct = (predicted == y_test).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}, accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for MLP (concatenation) - 54.74%\n",
    "#### The accuracy is better as compared to the simple models because it trains a neural network and takes context into conideration. This helps to improve the accuracy. The one without 10 vectors gives better accuracy as it considers all the words rather than only 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "### https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "#### epochs = 10\n",
    "#### Loss - Cross entropy Loss\n",
    "#### Adam Optimizer\n",
    "#### lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, hidden = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model = RNNModel(6000, 20, 3).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of reviews and their word vec concatenated until 20 words\n",
    "data_tr_rnn = []\n",
    "for review in df_new['review_body'].tolist():\n",
    "    #print(review)\n",
    "    data_temp_rnn = []\n",
    "    for i, word in enumerate(review.split()):\n",
    "        #print(i, word)\n",
    "        if i<20 and word in words:\n",
    "            data_temp_rnn.append(wv[word])\n",
    "    if len(data_temp_rnn) < 20:\n",
    "        while len(data_temp_rnn) != 20:\n",
    "            data_temp_rnn.append(np.zeros(shape=(300,)))\n",
    "    data_tr_rnn.append(np.array(data_temp_rnn, dtype=np.float32).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_tr_rnn, df_new['star_rating'].tolist(), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_tn = torch.from_numpy(np.array(X_train))\n",
    "testX_tn = torch.from_numpy(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY_tn = torch.from_numpy(np.array(y_train))\n",
    "testY_tn = torch.from_numpy(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_tn = TensorDataset(trainX_tn, trainY_tn)\n",
    "test_dataset_tn = TensorDataset(testX_tn, testY_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset_tn, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset_tn, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [750/1500], Loss: 0.9000\n",
      "Epoch [1/10], Step [1500/1500], Loss: 0.7904\n",
      "Epoch [2/10], Step [750/1500], Loss: 0.7196\n",
      "Epoch [2/10], Step [1500/1500], Loss: 0.6597\n",
      "Epoch [3/10], Step [750/1500], Loss: 0.5783\n",
      "Epoch [3/10], Step [1500/1500], Loss: 0.6027\n",
      "Epoch [4/10], Step [750/1500], Loss: 0.4388\n",
      "Epoch [4/10], Step [1500/1500], Loss: 0.5562\n",
      "Epoch [5/10], Step [750/1500], Loss: 0.3315\n",
      "Epoch [5/10], Step [1500/1500], Loss: 0.5119\n",
      "Epoch [6/10], Step [750/1500], Loss: 0.2427\n",
      "Epoch [6/10], Step [1500/1500], Loss: 0.4162\n",
      "Epoch [7/10], Step [750/1500], Loss: 0.1509\n",
      "Epoch [7/10], Step [1500/1500], Loss: 0.2818\n",
      "Epoch [8/10], Step [750/1500], Loss: 0.1091\n",
      "Epoch [8/10], Step [1500/1500], Loss: 0.1320\n",
      "Epoch [9/10], Step [750/1500], Loss: 0.0860\n",
      "Epoch [9/10], Step [1500/1500], Loss: 0.0889\n",
      "Epoch [10/10], Step [750/1500], Loss: 0.0639\n",
      "Epoch [10/10], Step [1500/1500], Loss: 0.0595\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in enumerate(train_loader):  \n",
    "        data = data.reshape(batch_size, -1, 6000)\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 750 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 52.65 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data, labels in test_loader:\n",
    "        data = data.reshape(batch_size, -1, 6000)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy : {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Accuracy - 52.65%\n",
    "#### FNN with avg vectors mostly performs better than simple RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, hidden = self.gru(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUModel(6000, 20, 3).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [750/1500], Loss: 0.7281\n",
      "Epoch [1/10], Step [1500/1500], Loss: 0.6550\n",
      "Epoch [2/10], Step [750/1500], Loss: 0.6033\n",
      "Epoch [2/10], Step [1500/1500], Loss: 0.5467\n",
      "Epoch [3/10], Step [750/1500], Loss: 0.5184\n",
      "Epoch [3/10], Step [1500/1500], Loss: 0.4596\n",
      "Epoch [4/10], Step [750/1500], Loss: 0.4197\n",
      "Epoch [4/10], Step [1500/1500], Loss: 0.3891\n",
      "Epoch [5/10], Step [750/1500], Loss: 0.2989\n",
      "Epoch [5/10], Step [1500/1500], Loss: 0.2902\n",
      "Epoch [6/10], Step [750/1500], Loss: 0.2075\n",
      "Epoch [6/10], Step [1500/1500], Loss: 0.1958\n",
      "Epoch [7/10], Step [750/1500], Loss: 0.1576\n",
      "Epoch [7/10], Step [1500/1500], Loss: 0.1135\n",
      "Epoch [8/10], Step [750/1500], Loss: 0.1366\n",
      "Epoch [8/10], Step [1500/1500], Loss: 0.1021\n",
      "Epoch [9/10], Step [750/1500], Loss: 0.1333\n",
      "Epoch [9/10], Step [1500/1500], Loss: 0.0352\n",
      "Epoch [10/10], Step [750/1500], Loss: 0.0801\n",
      "Epoch [10/10], Step [1500/1500], Loss: 0.0441\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        data = data.reshape(batch_size, -1, 6000)\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 750 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 52.09166666666667 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data, labels in test_loader:\n",
    "#         images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "#         labels = labels.to(device)\n",
    "        data = data.reshape(batch_size, -1, 6000)\n",
    "        outputs = model(data)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy : {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU accuracy == 52.092%\n",
    "#### FNN with avg vectors mostly performs better than GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_dim).to(device)\n",
    "        out, hidden = self.lstm(x, (h0,c0))\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(6000, 20, 3).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [800/1500], Loss: 0.9832\n",
      "Epoch [2/10], Step [800/1500], Loss: 0.7546\n",
      "Epoch [3/10], Step [800/1500], Loss: 0.5776\n",
      "Epoch [4/10], Step [800/1500], Loss: 0.4471\n",
      "Epoch [5/10], Step [800/1500], Loss: 0.3370\n",
      "Epoch [6/10], Step [800/1500], Loss: 0.2400\n",
      "Epoch [7/10], Step [800/1500], Loss: 0.1750\n",
      "Epoch [8/10], Step [800/1500], Loss: 0.1185\n",
      "Epoch [9/10], Step [800/1500], Loss: 0.0954\n",
      "Epoch [10/10], Step [800/1500], Loss: 0.0756\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, labels) in enumerate(train_loader):\n",
    "        data = data.reshape(batch_size, -1, 6000)\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 800 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 52.94166666666667 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data, labels in test_loader:\n",
    "#         images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "#         labels = labels.to(device)\n",
    "        data = data.reshape(batch_size, -1, 6000)\n",
    "        outputs = model(data)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy : {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Accuracy - 52.94%\n",
    "#### FNN with avg vectors mostly performs better than LSTM \n",
    "#### The accuracies of GRU and LSTM is better than simple RNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "264be1201b42aa140e2ad84e9107c350c4bb4ff3e26b600f7907faf12d14c73d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
